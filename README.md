# go-crawler

1. error handling & retries + backoff whatever
2. check robots
3. count external links & add to report
4. save report as csv (email it as well?)
5. set up a chron for the above
6. follow external links???
